{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32194097-485d-4e2d-ba86-50440fd3307a",
   "metadata": {},
   "source": [
    "# This notebook is for reference only\n",
    "It relies on the Prolific ID of some participants, which has been redacted to ensure anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db71c580-564c-4731-9e67-989843f6bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c28bdf23-c192-4771-8f94-e3a5c05d9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOULD_SCRUB_ID = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b3eb21-7514-4876-a9fa-f34a56b9e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = sorted(glob('../data/*.csv'))[-1] # retrieve latest dataset\n",
    "OUTPUT_DIR = '../data/processed'\n",
    "\n",
    "ID_BLACKLIST = [\n",
    "    # REDACTED\n",
    "]\n",
    "\n",
    "ID_OVERCONFIDENT_PROGRAMMERS = [\n",
    "    # REDACTED\n",
    "]\n",
    "\n",
    "ID_OVERCONFIDENT_WEB3 = [\n",
    "    # REDACTED\n",
    "]\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d20799-464c-49a5-960c-a97bd6d3fad6",
   "metadata": {},
   "source": [
    "# Load\n",
    "- Eliminate unnamed columns\n",
    "- Remove non-prolific entries\n",
    "- Remove full question text (use short question name only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13bf5c0-2c48-45d3-9d13-0b80d5b4823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 entries loaded.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH, skiprows=[1])\n",
    "\n",
    "# remove unnamed columns\n",
    "cols = df.columns\n",
    "df = df[[c for c in cols if not c.startswith(\"Unnamed:\")]]\n",
    "\n",
    "# remove non-prolific entries\n",
    "df = df[df['id'].notnull()]\n",
    "df = df[df['id'] != 'Doris']\n",
    "\n",
    "# remove blacklisted rows\n",
    "df = df[~df['id'].isin(ID_BLACKLIST)]\n",
    "\n",
    "# CORRECTIONS\n",
    "# guy who mistakenly says he owns usdt\n",
    "df.loc[df['usdt_main_storage'] == \"I don't own USDT\", 'usdt_main_storage'] = np.nan\n",
    "\n",
    "# remove old data on metamask efficiency(diff qn phrasing)\n",
    "df.loc[df['mm_discover_fail_num'].isnull(), 'mm_discover_succeed_full_num'] = np.nan\n",
    "df.loc[df['mm_discover_fail_num'].isnull(), 'mm_understand_succeed_full_num'] = np.nan\n",
    "\n",
    "print(f\"{len(df)} entries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95668a29-607e-4680-895c-eb51a0368857",
   "metadata": {},
   "source": [
    "# Add sources columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ebfab48-4467-4fec-953f-9f114d2fb9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Medium article': 41,\n",
       "         'The smart contract code': 25,\n",
       "         'YouTube video': 89,\n",
       "         'Information from other people': 64,\n",
       "         'Google': 1,\n",
       "         'Whitepaper/greypaper': 42,\n",
       "         'Etherscan': 30,\n",
       "         'Official documentation that is not the whitepaper/greypaper': 18,\n",
       "         'Experience moving assets over the years': 1,\n",
       "         'and many mistakes.': 1,\n",
       "         'Security tools (e.g. MythX)': 9,\n",
       "         'cold storage wallet transfers': 1,\n",
       "         'Reddit': 1,\n",
       "         'BSCSCAN': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# what sources are there?\n",
    "srcs = Counter()\n",
    "for l in df.sources.str.split(', '):\n",
    "    if not isinstance(l, list):\n",
    "        continue\n",
    "    srcs = srcs + Counter(l)\n",
    "        \n",
    "srcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb526c3-3e6c-4984-904d-61ba44701e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_BLOCKCHAIN_EXPLORER = 'is_source_blockchain_explorer'\n",
    "SRC_CODE = 'is_source_code'\n",
    "SRC_MEDIUM = 'is_source_medium'\n",
    "SRC_OFFICIAL_NONPAPER = 'is_source_official_nonpaper'\n",
    "SRC_OFFICIAL_PAPER = 'is_source_official_paper'\n",
    "SRC_OTHER_PEOPLE = 'is_source_other_people'\n",
    "SRC_SECURITY_TOOL = 'is_source_security_tool'\n",
    "SRC_YOUTUBE = 'is_source_youtube'\n",
    "\n",
    "SRC_COLS_ATOMIC = [\n",
    "    SRC_BLOCKCHAIN_EXPLORER,\n",
    "    SRC_CODE,\n",
    "    SRC_MEDIUM,\n",
    "    SRC_OFFICIAL_NONPAPER,\n",
    "    SRC_OFFICIAL_PAPER,\n",
    "    SRC_OTHER_PEOPLE,\n",
    "    SRC_SECURITY_TOOL,\n",
    "    SRC_YOUTUBE\n",
    "]\n",
    "\n",
    "SRC_COLS_OFFICIAL = [SRC_CODE, SRC_OFFICIAL_NONPAPER, SRC_OFFICIAL_PAPER]\n",
    "\n",
    "SRC_OFFICIAL = 'is_used_official_source'\n",
    "SRC_UNOFFICIAL = 'is_used_unofficial_source'\n",
    "\n",
    "SRC_COLS_AGG = [\n",
    "    SRC_OFFICIAL,\n",
    "    SRC_UNOFFICIAL\n",
    "]\n",
    "\n",
    "SRCS = {\n",
    "    SRC_BLOCKCHAIN_EXPLORER: {'Etherscan', 'BSCSCAN'},\n",
    "    SRC_CODE: 'The smart contract code',\n",
    "    SRC_MEDIUM: 'Medium article',\n",
    "    SRC_OFFICIAL_NONPAPER: 'Official documentation that is not the whitepaper/greypaper',\n",
    "    SRC_OFFICIAL_PAPER: 'Whitepaper/greypaper',\n",
    "    SRC_OTHER_PEOPLE: 'Information from other people',\n",
    "    SRC_SECURITY_TOOL: 'Security tools (e.g. MythX)',\n",
    "    SRC_YOUTUBE: 'YouTube video',\n",
    "}\n",
    "\n",
    "for src, matches in SRCS.items():\n",
    "    if not isinstance(matches, set):\n",
    "        matches = {matches}\n",
    "        \n",
    "    f = lambda l: any(m in l for m in matches) if isinstance(l, list) else  np.nan\n",
    "    df[src] = df.sources.str.split(', ').apply(f)\n",
    "    \n",
    "    \n",
    "# src official\n",
    "df[SRC_OFFICIAL] = df[SRC_CODE] | df[SRC_OFFICIAL_PAPER] | df[SRC_OFFICIAL_NONPAPER]\n",
    "df.loc[df['sources'].isnull(), SRC_OFFICIAL] = np.nan\n",
    "\n",
    "# src unofficial\n",
    "df[SRC_UNOFFICIAL] = df[SRC_BLOCKCHAIN_EXPLORER] | df[SRC_MEDIUM] | df[SRC_OTHER_PEOPLE] | df[SRC_SECURITY_TOOL] | df[SRC_YOUTUBE]\n",
    "df.loc[df['sources'].isnull(), SRC_UNOFFICIAL] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44872cca-a9fe-483e-bd6d-fb73587853ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set values for expl_pref\n",
    "| Original | New |\n",
    "|---|---|\n",
    "| Diagram Description type | diag |\n",
    "| Natural Language Description Type | natlang |\n",
    "| Both are equally good | indifferent_positive |\n",
    "| Neither (both are equally bad) | indifferent_negative |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f111c62-e2b5-43f1-9405-63670e4d24b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expl_pref'] = df['expl_pref'].replace({\n",
    "    'Diagram Description type': 'diag',\n",
    "    'Natural Language Description type': 'natlang',\n",
    "    'Both are equally good': 'indifferent_positive',\n",
    "    'Neither (both are equally bad)': 'indifferent_negative',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4e923-bd58-4e62-9d02-4be057c9c8c8",
   "metadata": {},
   "source": [
    "# Add Explanation Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b59c97-4644-41b7-8d06-439e55d00fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_expl_prefers_natlang'] = df['expl_pref'] == 'natlang'\n",
    "df['is_expl_prefers_diag'] = df['expl_pref'] == 'diag'\n",
    "df['is_expl_prefers_indifferent_positive'] = df['expl_pref'] == 'indifferent_positive'\n",
    "df['is_expl_prefers_indifferent_negative'] = df['expl_pref'] == 'indifferent_negative'\n",
    "df['is_expl_prefers_indifferent_negative'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85744fb-91ec-429b-b59a-265f2558c033",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add Proficiency Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fc53e3-ada0-4421-9696-6ce9142efe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_WEB3 = 'is_web3'\n",
    "IS_NOT_WEB3 = 'is_not_web3'\n",
    "df[IS_WEB3] = df['web3_proficiency_num'] > 1\n",
    "df[IS_NOT_WEB3] = ~df[IS_WEB3]\n",
    "\n",
    "IS_GOOD_WEB3 = 'is_good_web3'\n",
    "IS_NOT_GOOD_WEB3 = 'is_not_good_web3'\n",
    "df[IS_GOOD_WEB3] = (df['web3_proficiency_num'] > 3) & (~df['id'].isin(ID_OVERCONFIDENT_WEB3))\n",
    "df[IS_NOT_GOOD_WEB3] = ~df[IS_GOOD_WEB3]\n",
    "\n",
    "IS_PROGRAMMER = 'is_programmer'\n",
    "IS_NOT_PROGRAMMER = 'is_not_programmer'\n",
    "df[IS_PROGRAMMER] = df['programming_proficiency_num'] > 1\n",
    "df[IS_NOT_PROGRAMMER] = ~df[IS_PROGRAMMER]\n",
    "\n",
    "IS_GOOD_PROGRAMMER = 'is_good_programmer'\n",
    "IS_NOT_GOOD_PROGRAMMER = 'is_not_good_programmer'\n",
    "df[IS_GOOD_PROGRAMMER] = (df['programming_proficiency_num'] > 3) & (~df['id'].isin(ID_OVERCONFIDENT_PROGRAMMERS))\n",
    "df[IS_NOT_GOOD_PROGRAMMER] = ~df[IS_GOOD_PROGRAMMER]\n",
    "\n",
    "IS_GOOD_ANTICIPATE_BEHAVIOR = 'is_good_anticipate_behavior'\n",
    "IS_NOT_GOOD_ANTICIPATE_BEHAVIOR = 'is_not_good_anticipate_behavior'\n",
    "df[IS_GOOD_ANTICIPATE_BEHAVIOR] = df['anticipate_behavior_num'] > 3\n",
    "df[IS_NOT_GOOD_ANTICIPATE_BEHAVIOR] = ~df[IS_GOOD_ANTICIPATE_BEHAVIOR]\n",
    "\n",
    "IS_GOOD_TRUST_BEHAVIOR = 'is_good_trust_behavior'\n",
    "IS_NOT_GOOD_TRUST_BEHAVIOR = 'is_not_good_trust_behavior'\n",
    "df[IS_GOOD_TRUST_BEHAVIOR] = df['trust_behavior_num'] > 3\n",
    "df[IS_NOT_GOOD_TRUST_BEHAVIOR] = ~df[IS_GOOD_TRUST_BEHAVIOR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e2d67-30d2-48d4-9e69-bd9d9f68c974",
   "metadata": {},
   "source": [
    "# Add USDT Main Storage Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52b5845-4ffb-4a8d-a2b5-bedce9a95f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usdt_main_storage\n",
       "Exchange (e.g. Binance)                 31\n",
       "Ethereum Wallet (e.g. MetaMask)         21\n",
       "Nexo                                     1\n",
       "ETH wallet via Ledger NanoX              1\n",
       "C4W                                      1\n",
       "cold storage hardware wallet             1\n",
       "No longer own - but was in a wallet.     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAIN_STORAGE_WALLET = 'is_usdt_main_storage_wallet'\n",
    "MAIN_STORAGE_NONWALLET = 'is_usdt_main_storage_nonwallet'\n",
    "\n",
    "df[MAIN_STORAGE_WALLET] = df['usdt_main_storage'].isin([\n",
    "    'Ethereum Wallet (e.g. MetaMask)',\n",
    "    'ETH wallet via Ledger NanoX',\n",
    "    'cold storage hardware wallet'\n",
    "])\n",
    "df.loc[df['usdt_main_storage'].isnull(), MAIN_STORAGE_WALLET] = np.nan\n",
    "\n",
    "df[MAIN_STORAGE_NONWALLET] = df['usdt_main_storage'].isin([\n",
    "    'Exchange (e.g. Binance)',\n",
    "    'Nexo',\n",
    "    'C4W' # some kinda reward pool idk lmao\n",
    "])\n",
    "df.loc[df['usdt_main_storage'].isnull(), MAIN_STORAGE_NONWALLET] = np.nan\n",
    "\n",
    "df.usdt_main_storage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdff1bc-129d-4364-bdee-37570f70b2f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Change `aware` â†’ `unaware`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ffab916-8b0a-4313-9e24-704119bf25f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grj_consortium_reject_aware_num grj_consortium_reject_unaware_num\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5      5.0\n",
       "6      5.0\n",
       "7      4.0\n",
       "8      5.0\n",
       "9      5.0\n",
       "      ... \n",
       "126    5.0\n",
       "127    3.0\n",
       "128    5.0\n",
       "129    3.0\n",
       "130    4.0\n",
       "Name: grj_consortium_reject_unaware_num, Length: 121, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grj_consortium_reject_aware_why grj_consortium_reject_unaware_why\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5                                             didnt know\n",
       "6                               I didn't know the reason\n",
       "7           I didn't know transactions could be rejected\n",
       "8      i was unaware there could be votes on transact...\n",
       "9              Why could other people decide what i send\n",
       "                             ...                        \n",
       "126                             not sure that`s possible\n",
       "127                                         I'm not sure\n",
       "128                            I have no idea about this\n",
       "129                                        I wasnt sure.\n",
       "130                            I didn't know about this.\n",
       "Name: grj_consortium_reject_unaware_why, Length: 121, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prj_consortium_reject_aware_num prj_consortium_reject_unaware_num\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5      5.0\n",
       "6      4.0\n",
       "7      5.0\n",
       "8      5.0\n",
       "9      2.0\n",
       "      ... \n",
       "126    5.0\n",
       "127    5.0\n",
       "128    4.0\n",
       "129    4.0\n",
       "130    4.0\n",
       "Name: prj_consortium_reject_unaware_num, Length: 121, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prj_consortium_reject_aware_why prj_consortium_reject_unaware_why\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5      I dont even know what  \"a consortium of Tether...\n",
       "6                 They wouldn't known the reason of this\n",
       "7      I didn't know that was possible to reject tran...\n",
       "8      i wasn't aware voting could take place for tra...\n",
       "9                                        prior in survey\n",
       "                             ...                        \n",
       "126                                     would not happen\n",
       "127    I don't think meetings are collected with such...\n",
       "128    This is surprising to me because they charged ...\n",
       "129               I wasn't aware that that could happen.\n",
       "130                     I had no idea this could happen.\n",
       "Name: prj_consortium_reject_unaware_why, Length: 121, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = 6 - df[col]\n",
      "/var/folders/k8/zk3t1hw970s24hcwklx_31ww0000gn/T/ipykernel_75102/1295994774.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col_name] = df[col]\n"
     ]
    }
   ],
   "source": [
    "aware_cols = [c for c in df.columns if '_aware' in c]\n",
    "for col in aware_cols:\n",
    "    new_col_name = col.replace('aware', 'unaware')\n",
    "    if col.endswith('num'):\n",
    "        df[new_col_name] = 6 - df[col]\n",
    "    else:\n",
    "        df[new_col_name] = df[col]\n",
    "    if 'consortium_reject' in col:\n",
    "        print(col, new_col_name)\n",
    "        display(df[new_col_name])\n",
    "    del df[col]\n",
    "    \n",
    "df = df[sorted(df.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb99b3e-a365-4244-80a3-a1ac29b14fca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make binary columns into boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7d1df-4758-4937-bf5d-3be3ff68806f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLS = [\n",
    "    'is_usdt_owned',\n",
    "    'is_usdt_transferred_from_wallet',\n",
    "    'is_usdt_transferred_to_wallet',\n",
    "    \"is_read_code\",\n",
    "    \"is_believe_tether_decentralized\",\n",
    "]\n",
    "\n",
    "for col in COLS:\n",
    "    df.loc[df[col] == 'Yes', col.replace('is_', 'is_not_')] = False\n",
    "    df.loc[df[col] == 'Yes', col] = True\n",
    "    df.loc[df[col] == 'No', col.replace('is_', 'is_not_')] = True\n",
    "    df.loc[df[col] == 'No', col] = False\n",
    "df[COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc4e63-c8c2-42cb-bef4-d2429cce712c",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b089799e-937d-4646-be0c-4cb342369e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../data/processed/2023-08-02_1020.csv\n"
     ]
    }
   ],
   "source": [
    "filename = datetime.now().strftime(\"%Y-%m-%d_%H%M.csv\")\n",
    "path = os.path.join(OUTPUT_DIR, filename)\n",
    "data = df\n",
    "if SHOULD_SCRUB_ID:\n",
    "    data = data[[c for c in data.columns if c != 'id']]\n",
    "    data = data[[c for c in data.columns if c != 'prolific_id']]\n",
    "df.to_csv(path)\n",
    "print(f'Saved to {path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
